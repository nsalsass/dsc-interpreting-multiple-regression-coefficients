{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting One-Hot Encoded Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "You have already seen some examples of how to interpret coefficients for multiple linear regression. In this lesson we will go over some more examples, particularly focusing on models with one-hot encoded categorical predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Describe and apply the concept of a reference category\n",
    "* Interpret coefficients for one-hot encoded variables\n",
    "* Explain the implications of binning and dropping multiple categories with one-hot encoded variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Categories\n",
    "\n",
    "Let's look at the Auto MPG dataset, with an engineered `make` feature. Then we'll start with a multiple regression model that uses `weight`, `model year`, and `origin` to predict `mpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "      <th>make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>chevrolet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>buick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>plymouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>amc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "      <td>ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "      <td>vw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "      <td>dodge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "      <td>ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "      <td>chevy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0          8         307.0         130    3504          12.0   \n",
       "1    15.0          8         350.0         165    3693          11.5   \n",
       "2    18.0          8         318.0         150    3436          11.0   \n",
       "3    16.0          8         304.0         150    3433          12.0   \n",
       "4    17.0          8         302.0         140    3449          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "387  27.0          4         140.0          86    2790          15.6   \n",
       "388  44.0          4          97.0          52    2130          24.6   \n",
       "389  32.0          4         135.0          84    2295          11.6   \n",
       "390  28.0          4         120.0          79    2625          18.6   \n",
       "391  31.0          4         119.0          82    2720          19.4   \n",
       "\n",
       "     model year  origin                   car name       make  \n",
       "0            70       1  chevrolet chevelle malibu  chevrolet  \n",
       "1            70       1          buick skylark 320      buick  \n",
       "2            70       1         plymouth satellite   plymouth  \n",
       "3            70       1              amc rebel sst        amc  \n",
       "4            70       1                ford torino       ford  \n",
       "..          ...     ...                        ...        ...  \n",
       "387          82       1            ford mustang gl       ford  \n",
       "388          82       2                  vw pickup         vw  \n",
       "389          82       1              dodge rampage      dodge  \n",
       "390          82       1                ford ranger       ford  \n",
       "391          82       1                 chevy s-10      chevy  \n",
       "\n",
       "[392 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data into pandas and engineer \"make\" feature\n",
    "data = pd.read_csv(\"auto-mpg.csv\")\n",
    "data[\"make\"] = data[\"car name\"].str.split().apply(lambda x: x[0])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare y and X for modeling\n",
    "y = data[\"mpg\"]\n",
    "X = data[[\"weight\", \"model year\", \"origin\"]]\n",
    "\n",
    "# origin is categorical and needs to be numeric to run regression\n",
    "X = pd.get_dummies(X, columns=[\"origin\"], drop_first=True, dtype=int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model displayed above, we have dropped one of the dummy variable columns for `origin`, in order to avoid the **dummy variable trap**. The dropped column is now our **reference category**.\n",
    "\n",
    "So, which column is that?\n",
    "\n",
    "To investigate this, we need to look at the values of `origin` prior to one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"origin\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(`1` means a US car maker, `2` means a European car maker, `3` means an Asian car maker.)\n",
    "\n",
    "Because `1` does not appear in our one-hot encoded variable (we only have `origin_2` and `origin_3`), we know that **`1` is the reference category**. Thus we can interpret the coefficients of `origin_2` and `origin_3` like this:\n",
    "\n",
    "* `origin_2` means the difference associated with a car being from a European car maker vs. a US car maker. In other words, compared to US car makers, we see an associated increase of about 2 MPG for European car makers.\n",
    "* `origin_3` means the difference associated with a car being from an Asian car maker vs. a US car maker. We see an associated increase of about 2.2 MPG for Asian car makers compared to US car makers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Reference Categories\n",
    "\n",
    "When you run `pd.get_dummies` and specify `drop_first=True`, this is an easy way to make sure that you avoid the dummy variable trap and that _some_ category is selected as the reference category. However there is no data understanding involved; pandas just chooses the first category (alphabetically) that it finds.\n",
    "\n",
    "If we skip that argument and manually drop a column instead, we can easily set any category as the reference category.\n",
    "\n",
    "For example, if we set `2` (European car maker) as the reference category, our model looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"weight\", \"model year\", \"origin\"]]\n",
    "X = pd.get_dummies(X, columns=[\"origin\"], dtype=int)\n",
    "X = X.drop(\"origin_2\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "\n",
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we set `3` (Asian car maker) as the reference category, our model looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"weight\", \"model year\", \"origin\"]]\n",
    "X = pd.get_dummies(X, columns=[\"origin\"], dtype=int)\n",
    "X = X.drop(\"origin_3\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "\n",
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the models above, what changes and what stays the same, in terms of the coefficients? Why?\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "    <summary style=\"cursor: pointer\"><b>Answer (click to reveal)</b></summary>\n",
    "    \n",
    "Each time the reference category changes, the `const` and the other `origin` coefficients change.\n",
    "\n",
    "`const` changes because it represents the value when _all_ predictors are 0, and this means that `const` represents when the reference category is true.\n",
    "\n",
    "The other `origin` coefficients change because they are always with respect to the reference category. So if the category `1` has been dropped, then `origin_2` is with respect to category `1`. But if category `3` has been dropped instead, then `origin_2` is with respect to category `3`.\n",
    "\n",
    "`weight` and `model year` don't change, because the `origin` overall is still being \"held constant\" by the model, regardless of how `origin` is actually encoded.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Reference Category\n",
    "\n",
    "Choosing an appropriate reference category comes down to your understanding of the data and the stakeholders. Is there a category that makes the most sense as a \"baseline\", \"default\", or \"neutral\" category?\n",
    "\n",
    "For our `origin` category, if you were performing this analysis in the US, then setting `origin_1` as the baseline might make the most sense. If your audience were in Europe or Asia, then it might make more sense to drop `origin_2` or `origin_3`. For a context without a clear match like this, you might choose the category that is most familiar or most well-known to your audience.\n",
    "\n",
    "You also might consider looking at the data itself to see what makes the most sense as a \"baseline\". If one category is much more common than the others, that might be a good baseline. Or if one category is in the \"middle\" (maybe closest to the mean or median) in terms of the target, that also might be a good baseline.\n",
    "\n",
    "**There is no single right answer for choosing a reference category.** The model contains the same information regardless of which category is chosen, so you are really just deciding how best to interpret your coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictors with More Categories\n",
    "\n",
    "The category `origin` only has three options for a reference category, since there are only three different values present in that column.\n",
    "\n",
    "What about `make`, which contains many more categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data[\"make\"], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just use `drop_first=True`, add this predictor to our other three, and see what the model outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"weight\", \"model year\", \"origin\", \"make\"]]\n",
    "X = pd.get_dummies(X, columns=[\"origin\", \"make\"], drop_first=True, dtype=int)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a long model summary! How can we make sense of this, particularly given that so many of these coefficients are not statistically significant?\n",
    "\n",
    "It's difficult to extract much meaning from the `make` variable here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Before doing anything else with categorical data, some ***data cleaning*** is often useful.\n",
    "\n",
    "Something you might notice here is that several of these different `make` values are \"really\" the same. For example, `\"chevroelt\"` is almost certainly a typo, that was intended to be `\"chevrolet\"`.\n",
    "\n",
    "What happens if we combine together values that seem like they really should be the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"make\"].nunique(), \"unique values\")\n",
    "data[\"make\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {\n",
    "    \"chevroelt\": \"chevrolet\",\n",
    "    \"mercedes\": \"mercedes-benz\",\n",
    "    \"toyouta\": \"toyota\",\n",
    "    \"vokswagen\": \"volkswagen\",\n",
    "    \"maxda\": \"mazda\",\n",
    "    \"chevy\": \"chevrolet\",\n",
    "    \"vw\": \"volkswagen\"\n",
    "}\n",
    "\n",
    "data.replace(replacement_dict, inplace=True)\n",
    "\n",
    "print(data[\"make\"].nunique(), \"unique values\")\n",
    "data[\"make\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"weight\", \"model year\", \"origin\", \"make\"]]\n",
    "X = pd.get_dummies(X, columns=[\"origin\", \"make\"], drop_first=True, dtype=int)\n",
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that didn't do much. We still have lots of coefficients that can't be interpreted because they aren't statistically significant.\n",
    "\n",
    "### Creating an \"Other\" Category\n",
    "\n",
    "Another approach you might consider is creating a catch-all \"other\" category for categories that don't have many examples in the dataset. We'll choose a somewhat-arbitrary cutoff of **10 observations**, which is a conventional cutoff for the number of samples you need per independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"make\"].value_counts()[data[\"make\"].value_counts() < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace = data[\"make\"].value_counts()[data[\"make\"].value_counts() < 10].index.values\n",
    "to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(to_replace, value=\"other\", inplace=True)\n",
    "\n",
    "print(data[\"make\"].nunique(), \"unique values\")\n",
    "data[\"make\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"weight\", \"model year\", \"origin\", \"make\"]]\n",
    "X = pd.get_dummies(X, columns=[\"origin\", \"make\"], drop_first=True, dtype=int)\n",
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a much more manageable number of coefficients. Let's go through and interpret these:\n",
    "\n",
    "* The **reference category** for `origin` is `1` (US) and for `make` is `amc` (American Motor Company)\n",
    "* `const`, `weight`, and `model year` are all still statistically significant\n",
    "  * When all other predictors are 0, the MPG would be about -18.3\n",
    "  * For each increase of 1 lb in weight, we see an associated decrease of about 0.006 in MPG\n",
    "  * For each year newer the vehicle is, we see an associated increase of about 0.75 in MPG\n",
    "* `origin_2` and `origin_3` are not statistically significant any more\n",
    "  * While this might seem surprising, our data understanding can explain it. The `origin` feature and the `make` feature are really providing the same information, except that `make` is more granular. Every `make` category (except for `other`) corresponds to exactly one `origin` category. Therefore it probably does not make sense to include both `origin` and `make` in the same model\n",
    "* At a standard alpha of 0.05, only `make_plymouth`, `make_pontiac`, and `make_volkswagen` are statistically significant\n",
    "  * When a car's make is `plymouth` compared to `amc`, we see an associated increase of about 2.4 in MPG\n",
    "  * When a car's make is `pontiac` compared to `amc`, we see an associated increase of about 2.9 in MPG\n",
    "  * When a car's make is `volkswagen` compared to `amc`, we see an associated increase of about 3.1 in MPG\n",
    "\n",
    "All of the significant coefficients happen to be positive. Why is that? It turns out that `amc` is the first `make` value alphabetically _and_ has the lowest mean MPG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"make\").mean('mpg').sort_values(by=\"mpg\")[[\"mpg\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might surprise you that out of these categories, `pontiac`, `plymouth`, and `volkswagen` were the only ones with statistically significant differences. You wouldn't guess that based on the means alone. But keep in mind that the t-test being used here takes into account the number and the variance in each category, not just the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Iteration\n",
    "\n",
    "We could stop there and have this be our final model. Coefficients that aren't statistically significant aren't a _problem_ for a model, they just mean that we can't interpret those coefficients because we don't have enough evidence that those coefficients aren't really zero.\n",
    "\n",
    "A lot of people who are just learning about linear regression modeling will try dropping all of the predictors whose coefficients aren't statistically significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"weight\", \"model year\", \"origin\", \"make\"]]\n",
    "X = pd.get_dummies(X, columns=[\"origin\", \"make\"], drop_first=True, dtype=int)\n",
    "\n",
    "not_significant = [\n",
    "    \"origin_2\",\n",
    "    \"origin_3\",\n",
    "    \"make_buick\",\n",
    "    \"make_chevrolet\",\n",
    "    \"make_datsun\",\n",
    "    \"make_dodge\",\n",
    "    \"make_ford\",\n",
    "    \"make_honda\",\n",
    "    \"make_mazda\",\n",
    "    \"make_mercury\",\n",
    "    \"make_oldsmobile\",\n",
    "    \"make_other\",\n",
    "    \"make_toyota\"\n",
    "]\n",
    "\n",
    "X.drop(not_significant, axis=1, inplace=True)\n",
    "\n",
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Don't do this!**\n",
    "\n",
    "First, what do these coefficients mean in this context? There are three different `model` values, so...\n",
    "\n",
    "* `make_plymouth` is the difference between having a `make` of `plymouth` and a `make` of...anything other than `plymouth`, `pontiac`, or `volkswagen`\n",
    "* `make_pontiac` is the difference between having a `make` of `pontiac` and a `make` of anything other than `plymouth`, `pontiac`, or `volkswagen`\n",
    "* `make_volkswagen` is the difference between having a `make` of `volkswagen` and a `make` of anything other than `plymouth`, `pontiac`, or `volkswagen`\n",
    "\n",
    "That \"anything other than\" category is no longer a useful reference category!\n",
    "\n",
    "Second, you did not actually solve the statistical significance problem by dropping all of those columns. Now that those other columns are gone, `make_plymouth` and `make_pontiac` are no longer statistically significant. This is because even though there was a statistically significant difference between `plymouth` and `amc`, and between `pontiac` and `amc`, the difference between these categories and the \"anything other than\" category is not statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better strategy would go back to our **data understanding** and remove columns that we have a good reason to believe are no longer useful. In this case that would be the `origin` columns, since `make` is already providing that same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"weight\", \"model year\", \"make\"]]\n",
    "X = pd.get_dummies(X, columns=[\"make\"], drop_first=True, dtype=int)\n",
    "\n",
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we made our modeling decision based on data understanding and not on p-values alone, we actually see that _more_ of our coefficients are significant than before.\n",
    "\n",
    "Let's go ahead and say that this is our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y, results.predict(sm.add_constant(X)), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Results\n",
    "\n",
    "Here we'll walk through a **narrative** version of our final model, starting from the beginning. It is fairly typical that your actual modeling process will not match the narrative you describe at the end, since the final version will be cleaned up and won't include extraneous details about things you tried that didn't work. For example, unless you had a specific reason to tell stakeholders why `origin` wasn't part of the final model, your final narrative can just skip over talking about `origin` at all, as this one does.\n",
    "\n",
    "### Data Understanding and Preparation\n",
    "\n",
    "Our final model included these features:\n",
    "\n",
    "* `weight`\n",
    "* `model year`\n",
    "* `make`\n",
    "\n",
    "We performed data cleaning on `make` to account for typos and alternative names, and also combined vehicles with fewer than 10 samples for their make into a single category called `other`. Then we one-hot encoded `make`, resulting in 14 dummy predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,5), sharey=True)\n",
    "ax1.set_ylabel(\"mpg\")\n",
    "\n",
    "data.plot.scatter(x=\"weight\", y=\"mpg\", ax=ax1)\n",
    "data.plot.scatter(x=\"model year\", y=\"mpg\", ax=ax2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "data.groupby(\"make\").mean('mpg').sort_values(by=\"mpg\").plot.bar(y=\"mpg\", ax=ax)\n",
    "ax.axhline(y=data[\"mpg\"].mean(), label=\"mean\", color=\"black\", linestyle=\"--\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Metrics\n",
    "\n",
    "These features were fed into an ordinary least-squares multiple regression model. This model:\n",
    "\n",
    "* is statistically significant overall (F-statistic p-value 5.53e-134)\n",
    "* explains about 82% of the variance in MPG (adjusted R-Squared 0.824)\n",
    "* is off by about 3.2 MPG in an average prediction (RMSE 3.2005653137923917)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Diagnostics\n",
    "\n",
    "Below are partial regression plots for all model features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "sm.graphics.plot_partregress_grid(\n",
    "    results,\n",
    "    exog_idx=list(X.columns),\n",
    "    grid=(4,4),\n",
    "    fig=fig)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation\n",
    "\n",
    "Below are all model coefficients and p-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([results.params, results.pvalues], axis=1)\n",
    "results_df.columns = [\"coefficient\", \"p-value\"]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are only coefficients with p-values below 0.05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df[results_df[\"p-value\"] < 0.05].sort_values(by=\"coefficient\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing this out:\n",
    "\n",
    "* For a car with `weight` and `model year` of 0 (i.e. weighing 0 lbs and built in 1900), as well as a `make` of `amc`, we would expect an MPG of about -17.6\n",
    "  * It's ok that this is not a valid MPG, since a car weighing 0 lbs is not valid either\n",
    "* For each increase of 1 lb in **weight**, we see an associated **decrease** in MPG of about .006\n",
    "* For each year **newer** of a model, we see an associated **increase** in MPG of about 0.75\n",
    "* Breaking down the `make`:\n",
    "  * For a **Plymouth** vehicle compared to an AMC vehicle, we see an associated **increase** in MPG of about 2.4\n",
    "  * For a **Toyota** vehicle compared to an AMC vehicle, we see an associated **increase** in MPG of about 2.5\n",
    "  * For a **Pontiac** vehicle compared to an AMC vehicle, we see an associated **increase** in MPG of about 3.0\n",
    "  * For a **Volkswagen** vehicle compared to an AMC vehicle, we see an associated **increase** in MPG of about 4.3\n",
    "  * For a **Honda** vehicle compared to an AMC vehicle, we see an associated **increase** in MPG of about 4.5\n",
    "  * For a **Datsun** vehicle compared to an AMC vehicle, we see an associated **increase** in MPG of about 4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.drop([\"const\", \"weight\", \"model year\", \"make_other\"]).plot.barh(y=\"coefficient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while we included `make` categories with higher p-values in the model, we did not report their coefficients. That is because we can't be confident that those coefficients aren't actually zero. Also we did not report a coefficient for `make_other` because this is not a particularly meaningful thing to explain to a stakeholder.\n",
    "\n",
    "We also aren't plotting the `make` values on the same graph as the `weight` and `model year` values because they are all measured in different units (lbs vs. years vs. vehicle make), so it doesn't really make sense to compare them. Whereas it might be interesting to a stakeholder to see just the `make` values compared against each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson you looked at several different multiple regression models, all built using one-hot encoded categorical features in addition to numeric features. You saw how the choice of a reference category impacts the interpretation of the coefficients, and also walked through several different examples of what to do and what not to do when you encounter a feature with many categories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
